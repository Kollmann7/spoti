{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1587f53",
   "metadata": {},
   "source": [
    "# Skills Matching (Pages → DB Compétences)\n",
    "\n",
    "- Charge le dernier CSV d'extraction dans `output/*with_content*.csv`.\n",
    "- Nettoie et normalise le texte extrait.\n",
    "- Applique des regex et règles pour identifier les compétences techniques.\n",
    "- Sauvegarde les résultats dans `results/skills_extracted_YYYYMMDD_HHMMSS.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2dbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Imports réalisés avec succès\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OUTPUT_DIR = Path('output')\n",
    "RESULTS_DIR = Path('results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Dossier de résultats: {RESULTS_DIR}\")\n",
    "print(f\"Dossier d'entrée: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586c713",
   "metadata": {},
   "source": [
    "## 1. Définition des compétences à rechercher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de données des compétences techniques\n",
    "COMPETENCES_TECHNIQUES = {\n",
    "    'Langages de programmation': [\n",
    "        'python', 'java', 'javascript', 'typescript', 'c#', 'c++', 'c', 'php', 'ruby', 'go', 'rust',\n",
    "        'swift', 'kotlin', 'scala', 'r', 'matlab', 'sql', 'html', 'css', 'sass', 'less'\n",
    "    ],\n",
    "    'Frameworks et bibliothèques': [\n",
    "        'react', 'angular', 'vue', 'node.js', 'express', 'django', 'flask', 'spring', 'laravel',\n",
    "        'symfony', 'rails', 'asp.net', '.net', 'bootstrap', 'jquery', 'tensorflow', 'pytorch',\n",
    "        'scikit-learn', 'pandas', 'numpy'\n",
    "    ],\n",
    "    'Bases de données': [\n",
    "        'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'sqlite', 'oracle',\n",
    "        'sql server', 'cassandra', 'neo4j', 'firebase'\n",
    "    ],\n",
    "    'Cloud et DevOps': [\n",
    "        'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'gitlab ci', 'github actions',\n",
    "        'terraform', 'ansible', 'vagrant', 'linux', 'ubuntu', 'centos', 'nginx', 'apache'\n",
    "    ],\n",
    "    'Outils et technologies': [\n",
    "        'git', 'svn', 'jira', 'confluence', 'slack', 'teams', 'figma', 'sketch', 'photoshop',\n",
    "        'illustrator', 'after effects', 'premiere pro', 'autocad', 'solidworks'\n",
    "    ],\n",
    "    'Méthodologies': [\n",
    "        'agile', 'scrum', 'kanban', 'devops', 'ci/cd', 'tdd', 'bdd', 'clean code',\n",
    "        'design patterns', 'microservices', 'api rest', 'graphql'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Compétences transversales\n",
    "COMPETENCES_TRANSVERSALES = {\n",
    "    'Communication': [\n",
    "        'communication', 'présentation', 'rédaction', 'négociation', 'relation client',\n",
    "        'animation d\\'équipe', 'formation', 'pédagogie'\n",
    "    ],\n",
    "    'Gestion de projet': [\n",
    "        'gestion de projet', 'planning', 'budget', 'coordination', 'organisation',\n",
    "        'suivi', 'reporting', 'analyse des risques'\n",
    "    ],\n",
    "    'Langues': [\n",
    "        'anglais', 'allemand', 'espagnol', 'italien', 'mandarin', 'arabe', 'russe',\n",
    "        'bilingue', 'trilingue', 'niveau b2', 'niveau c1', 'toeic', 'toefl'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Fusionner toutes les compétences\n",
    "TOUTES_COMPETENCES = {**COMPETENCES_TECHNIQUES, **COMPETENCES_TRANSVERSALES}\n",
    "\n",
    "print(f\"Nombre de catégories de compétences: {len(TOUTES_COMPETENCES)}\")\n",
    "total_skills = sum(len(skills) for skills in TOUTES_COMPETENCES.values())\n",
    "print(f\"Nombre total de compétences définies: {total_skills}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8695688",
   "metadata": {},
   "source": [
    "## 2. Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyer_texte(texte):\n",
    "    \"\"\"Nettoie et normalise le texte pour l'extraction de compétences.\"\"\"\n",
    "    if pd.isna(texte) or not isinstance(texte, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convertir en minuscules\n",
    "    texte = texte.lower()\n",
    "    \n",
    "    # Remplacer les caractères spéciaux par des espaces\n",
    "    texte = re.sub(r'[^\\\\w\\\\s./-]', ' ', texte)\n",
    "    \n",
    "    # Normaliser les espaces multiples\n",
    "    texte = re.sub(r'\\\\s+', ' ', texte)\n",
    "    \n",
    "    return texte.strip()\n",
    "\n",
    "def extraire_competences(texte, competences_dict):\n",
    "    \"\"\"Extrait les compétences trouvées dans le texte.\"\"\"\n",
    "    if not texte:\n",
    "        return {}\n",
    "    \n",
    "    competences_trouvees = {}\n",
    "    \n",
    "    for categorie, skills_list in competences_dict.items():\n",
    "        competences_trouvees[categorie] = []\n",
    "        \n",
    "        for skill in skills_list:\n",
    "            # Recherche avec limites de mots pour éviter les faux positifs\n",
    "            pattern = r'\\\\b' + re.escape(skill.lower()) + r'\\\\b'\n",
    "            if re.search(pattern, texte):\n",
    "                competences_trouvees[categorie].append(skill)\n",
    "    \n",
    "    # Supprimer les catégories vides\n",
    "    competences_trouvees = {k: v for k, v in competences_trouvees.items() if v}\n",
    "    \n",
    "    return competences_trouvees\n",
    "\n",
    "def compter_competences(liste_competences):\n",
    "    \"\"\"Compte les occurrences de chaque compétence.\"\"\"\n",
    "    compteur = Counter()\n",
    "    \n",
    "    for competences_doc in liste_competences:\n",
    "        for categorie, skills in competences_doc.items():\n",
    "            for skill in skills:\n",
    "                compteur[skill] += 1\n",
    "    \n",
    "    return compteur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f1999",
   "metadata": {},
   "source": [
    "## 3. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8adc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver le fichier CSV le plus récent\n",
    "csv_files = list(OUTPUT_DIR.glob('*with_content*.csv'))\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"Aucun fichier CSV trouvé dans {OUTPUT_DIR}\")\n",
    "\n",
    "# Prendre le plus récent\n",
    "latest_csv = sorted(csv_files)[-1]\n",
    "print(f\"Chargement du fichier: {latest_csv}\")\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(latest_csv)\n",
    "print(f\"Nombre de documents chargés: {len(df)}\")\n",
    "print(f\"Colonnes disponibles: {list(df.columns)}\")\n",
    "\n",
    "# Identifier la colonne de texte\n",
    "if 'extracted_text' in df.columns:\n",
    "    text_column = 'extracted_text'\n",
    "elif 'content' in df.columns:\n",
    "    text_column = 'content'\n",
    "else:\n",
    "    text_column = df.columns[-1]  # Dernière colonne par défaut\n",
    "\n",
    "print(f\"Colonne de texte utilisée: {text_column}\")\n",
    "print(f\"Documents avec du texte: {df[text_column].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee624598",
   "metadata": {},
   "source": [
    "## 4. Nettoyage et préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9831077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyer le texte\n",
    "print(\"Nettoyage du texte...\")\n",
    "df['texte_nettoye'] = df[text_column].apply(nettoyer_texte)\n",
    "\n",
    "# Filtrer les documents vides\n",
    "df_clean = df[df['texte_nettoye'].str.len() > 10].copy()\n",
    "print(f\"Documents après nettoyage: {len(df_clean)}\")\n",
    "\n",
    "# Statistiques sur la longueur du texte\n",
    "df_clean['longueur_texte'] = df_clean['texte_nettoye'].str.len()\n",
    "print(f\"Longueur moyenne du texte: {df_clean['longueur_texte'].mean():.0f} caractères\")\n",
    "print(f\"Longueur médiane du texte: {df_clean['longueur_texte'].median():.0f} caractères\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbfba57",
   "metadata": {},
   "source": [
    "## 5. Extraction des compétences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ba9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les compétences pour chaque document\n",
    "print(\"Extraction des compétences...\")\n",
    "\n",
    "competences_extraites = []\n",
    "for idx, row in df_clean.iterrows():\n",
    "    competences = extraire_competences(row['texte_nettoye'], TOUTES_COMPETENCES)\n",
    "    competences_extraites.append(competences)\n",
    "\n",
    "df_clean['competences'] = competences_extraites\n",
    "\n",
    "# Compter le nombre de compétences par document\n",
    "df_clean['nb_competences'] = df_clean['competences'].apply(\n",
    "    lambda x: sum(len(skills) for skills in x.values())\n",
    ")\n",
    "\n",
    "print(f\"Documents avec au moins une compétence: {(df_clean['nb_competences'] > 0).sum()}\")\n",
    "print(f\"Nombre moyen de compétences par document: {df_clean['nb_competences'].mean():.2f}\")\n",
    "print(f\"Maximum de compétences dans un document: {df_clean['nb_competences'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e908c",
   "metadata": {},
   "source": [
    "## 6. Analyse et statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e519274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les compétences les plus fréquentes\n",
    "compteur_competences = compter_competences(competences_extraites)\n",
    "competences_populaires = compteur_competences.most_common(20)\n",
    "\n",
    "print(\"Top 20 des compétences les plus fréquentes:\")\n",
    "for i, (skill, count) in enumerate(competences_populaires, 1):\n",
    "    print(f\"{i:2d}. {skill:<20} : {count:3d} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques par catégorie\n",
    "stats_categories = {}\n",
    "\n",
    "for categorie in TOUTES_COMPETENCES.keys():\n",
    "    # Compter les documents ayant au moins une compétence de cette catégorie\n",
    "    docs_avec_categorie = sum(1 for comp in competences_extraites if categorie in comp and comp[categorie])\n",
    "    \n",
    "    # Compter le total des compétences de cette catégorie\n",
    "    total_competences = sum(len(comp.get(categorie, [])) for comp in competences_extraites)\n",
    "    \n",
    "    stats_categories[categorie] = {\n",
    "        'documents': docs_avec_categorie,\n",
    "        'total_competences': total_competences,\n",
    "        'pourcentage_docs': (docs_avec_categorie / len(df_clean)) * 100\n",
    "    }\n",
    "\n",
    "print(\"\\\\nStatistiques par catégorie de compétences:\")\n",
    "print(f\"{'Catégorie':<25} {'Docs':<6} {'Total':<6} {'% Docs':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for categorie, stats in stats_categories.items():\n",
    "    print(f\"{categorie:<25} {stats['documents']:<6} {stats['total_competences']:<6} {stats['pourcentage_docs']:<6.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f0bbb",
   "metadata": {},
   "source": [
    "## 7. Préparation des résultats pour export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer le DataFrame de résultats\n",
    "resultats = []\n",
    "\n",
    "for idx, row in df_clean.iterrows():\n",
    "    doc_info = {\n",
    "        'filename': row.get('filename', f'doc_{idx}'),\n",
    "        'nb_competences_total': row['nb_competences'],\n",
    "        'longueur_texte': row['longueur_texte']\n",
    "    }\n",
    "    \n",
    "    # Ajouter les compétences par catégorie\n",
    "    for categorie in TOUTES_COMPETENCES.keys():\n",
    "        competences_cat = row['competences'].get(categorie, [])\n",
    "        doc_info[f'nb_{categorie.lower().replace(\" \", \"_\")}'] = len(competences_cat)\n",
    "        doc_info[f'{categorie.lower().replace(\" \", \"_\")}_liste'] = ', '.join(competences_cat)\n",
    "    \n",
    "    # Ajouter d'autres métadonnées si disponibles\n",
    "    for col in ['page_count', 'extraction_time']:\n",
    "        if col in row:\n",
    "            doc_info[col] = row[col]\n",
    "    \n",
    "    resultats.append(doc_info)\n",
    "\n",
    "df_resultats = pd.DataFrame(resultats)\n",
    "print(f\"DataFrame de résultats créé avec {len(df_resultats)} lignes et {len(df_resultats.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc1e82",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le nom de fichier avec timestamp\n",
    "timestamp = dt.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "fichier_resultats = RESULTS_DIR / f'skills_extracted_{timestamp}.csv'\n",
    "\n",
    "# Sauvegarder\n",
    "df_resultats.to_csv(fichier_resultats, index=False, encoding='utf-8')\n",
    "print(f\"Résultats sauvegardés dans: {fichier_resultats}\")\n",
    "\n",
    "# Sauvegarder aussi un résumé des statistiques\n",
    "fichier_stats = RESULTS_DIR / f'skills_stats_{timestamp}.json'\n",
    "import json\n",
    "\n",
    "resume_stats = {\n",
    "    'timestamp': timestamp,\n",
    "    'source_file': str(latest_csv),\n",
    "    'total_documents': len(df_clean),\n",
    "    'documents_avec_competences': (df_clean['nb_competences'] > 0).sum(),\n",
    "    'competences_les_plus_frequentes': dict(competences_populaires[:10]),\n",
    "    'stats_par_categorie': stats_categories\n",
    "}\n",
    "\n",
    "with open(fichier_stats, 'w', encoding='utf-8') as f:\n",
    "    json.dump(resume_stats, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Statistiques sauvegardées dans: {fichier_stats}\")\n",
    "print(\"\\\\nExtraction des compétences terminée avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248b2b0",
   "metadata": {},
   "source": [
    "## 9. Aperçu des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un aperçu des résultats\n",
    "print(\"Aperçu des premiers résultats:\")\n",
    "print(df_resultats.head())\n",
    "\n",
    "print(\"\\\\nColonnes disponibles dans les résultats:\")\n",
    "for i, col in enumerate(df_resultats.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\\\nNombre total de documents traités: {len(df_resultats)}\")\n",
    "print(f\"Taille du fichier de résultats: {fichier_resultats.stat().st_size / 1024:.1f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
